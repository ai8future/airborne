package provider

import (
	"context"
	"time"
)

// Provider defines the interface for AI providers
type Provider interface {
	// Name returns the provider identifier (e.g., "openai", "gemini", "anthropic")
	Name() string

	// GenerateReply generates a reply (blocking/unary)
	GenerateReply(ctx context.Context, params GenerateParams) (GenerateResult, error)

	// GenerateReplyStream generates a streaming reply
	GenerateReplyStream(ctx context.Context, params GenerateParams) (<-chan StreamChunk, error)

	// SupportsFileSearch returns true if provider supports RAG/file search
	SupportsFileSearch() bool

	// SupportsWebSearch returns true if provider supports web search grounding
	SupportsWebSearch() bool

	// SupportsNativeContinuity returns true if provider has native conversation continuity
	// (like OpenAI's response_id). If false, full history must be passed each time.
	SupportsNativeContinuity() bool

	// SupportsStreaming returns true if provider supports streaming responses
	SupportsStreaming() bool
}

// GenerateParams contains all parameters for generating a reply
type GenerateParams struct {
	// Instructions is the system prompt
	Instructions string

	// UserInput is the user's message
	UserInput string

	// ConversationHistory contains previous messages for context
	ConversationHistory []Message

	// FileStoreID is the vector store or file search store ID
	FileStoreID string

	// PreviousResponseID is for OpenAI conversation continuity
	PreviousResponseID string

	// OverrideModel overrides the default model
	OverrideModel string

	// EnableWebSearch enables web search grounding
	EnableWebSearch bool

	// EnableFileSearch enables RAG with file search
	EnableFileSearch bool

	// EnableCodeExecution enables code interpreter/execution
	EnableCodeExecution bool

	// FileIDToFilename maps file IDs to original filenames
	FileIDToFilename map[string]string

	// InlineImages contains images to include directly in the prompt
	InlineImages []InlineImage

	// Tools contains available tools/functions the model can call
	Tools []Tool

	// ToolResults contains results from previous tool calls (for multi-turn)
	ToolResults []ToolResult

	// Config contains provider-specific configuration
	Config ProviderConfig

	// RequestID for tracing
	RequestID string

	// ClientID identifies the calling client
	ClientID string

	// EnableStructuredOutput enables JSON mode with entity extraction (Gemini-only)
	EnableStructuredOutput bool
}

// Tool defines a function that the model can call
type Tool struct {
	// Name of the tool (must be a valid identifier)
	Name string

	// Description of what the tool does
	Description string

	// ParametersSchema is the JSON Schema for parameters
	ParametersSchema string

	// Strict requires strict JSON schema adherence (OpenAI-specific)
	Strict bool
}

// ToolCall represents the model's request to invoke a tool
type ToolCall struct {
	// ID is the unique identifier for this tool call
	ID string

	// Name of the tool to invoke
	Name string

	// Arguments as JSON string
	Arguments string
}

// ToolResult contains the output from a tool execution
type ToolResult struct {
	// ToolCallID matches the ToolCall.ID
	ToolCallID string

	// Output from the tool
	Output string

	// IsError indicates if the tool execution failed
	IsError bool
}

// CodeExecutionResult contains output from code execution
type CodeExecutionResult struct {
	// Code that was executed
	Code string

	// Language of the code
	Language string

	// Stdout from execution
	Stdout string

	// Stderr from execution
	Stderr string

	// ExitCode (0 = success)
	ExitCode int

	// Files generated by execution
	Files []GeneratedFile
}

// GeneratedFile represents a file created during code execution
type GeneratedFile struct {
	// Name of the file
	Name string

	// MIMEType of the file
	MIMEType string

	// Content of the file
	Content []byte
}

// Message represents a conversation message
type Message struct {
	Role      string
	Content   string
	Timestamp time.Time
}

// InlineImage represents an image to include directly in the prompt
type InlineImage struct {
	URI      string
	MIMEType string
	Filename string
}

// GeneratedImage represents an image produced by an image generation service
type GeneratedImage struct {
	// Data contains the raw image bytes (typically JPEG)
	Data []byte

	// MIMEType of the image (e.g., "image/jpeg", "image/png")
	MIMEType string

	// Prompt used to generate this image
	Prompt string

	// AltText for accessibility
	AltText string

	// Width in pixels
	Width int

	// Height in pixels
	Height int

	// ContentID for email embedding (cid:xxx)
	ContentID string
}

// StructuredMetadata contains extracted metadata from structured output mode
type StructuredMetadata struct {
	// Intent classification (question, request, task_delegation, feedback, complaint, follow_up, attachment_analysis)
	Intent string

	// RequiresUserAction is true if the response asks a clarifying question
	RequiresUserAction bool

	// Entities are named entities extracted from the text
	Entities []StructuredEntity

	// Topics are 2-4 keyword tags
	Topics []string

	// Scheduling contains calendar/meeting signals
	Scheduling *SchedulingIntent
}

// StructuredEntity represents an extracted named entity
type StructuredEntity struct {
	// Name is the entity name as it appears in text
	Name string

	// Type is the entity type (person, organization, location, product, technology, tool, service, etc.)
	Type string
}

// SchedulingIntent contains calendar/meeting signals
type SchedulingIntent struct {
	// Detected is true if scheduling intent was detected
	Detected bool

	// DatetimeMentioned is the raw text like "next Tuesday at 2pm"
	DatetimeMentioned string
}

// ProviderConfig contains provider-specific configuration
type ProviderConfig struct {
	APIKey          string
	Model           string
	Temperature     *float64
	TopP            *float64
	MaxOutputTokens *int
	BaseURL         string
	ExtraOptions    map[string]string
}

// GenerateResult contains the generated reply
type GenerateResult struct {
	// Text is the generated response
	Text string

	// ResponseID is for conversation continuity (OpenAI)
	ResponseID string

	// Usage contains token usage metrics
	Usage *Usage

	// Citations contains source citations
	Citations []Citation

	// Model is the actual model used
	Model string

	// ToolCalls contains tools the model wants to invoke
	ToolCalls []ToolCall

	// RequiresToolOutput is true if client must provide tool results
	RequiresToolOutput bool

	// CodeExecutions contains results from code execution
	CodeExecutions []CodeExecutionResult

	// Images contains AI-generated images
	Images []GeneratedImage

	// StructuredMetadata contains extracted intent, entities, topics (when structured output enabled)
	StructuredMetadata *StructuredMetadata

	// RequestJSON contains the raw API request for debugging
	RequestJSON []byte

	// ResponseJSON contains the raw API response for debugging
	ResponseJSON []byte
}

// HasImages returns true if the result contains generated images
func (r GenerateResult) HasImages() bool {
	return len(r.Images) > 0
}

// Usage contains token usage metrics
type Usage struct {
	InputTokens  int64
	OutputTokens int64
	TotalTokens  int64
}

// Citation represents a source citation
type Citation struct {
	Type       CitationType
	Provider   string
	URL        string
	Title      string
	FileID     string
	Filename   string
	Snippet    string
	StartIndex int
	EndIndex   int
	BrokenLink bool
}

// CitationType indicates the citation source type
type CitationType int

const (
	CitationTypeUnknown CitationType = iota
	CitationTypeURL
	CitationTypeFile
)

// StreamChunk represents a chunk in a streaming response
type StreamChunk struct {
	Type               ChunkType
	Text               string
	Index              int
	Usage              *Usage
	Citation           *Citation
	ResponseID         string
	Model              string
	Error              error
	ErrorCode          string
	Retryable          bool
	ToolCall           *ToolCall
	CodeExecution      *CodeExecutionResult
	ToolCalls          []ToolCall
	RequiresToolOutput bool
	CodeExecutions     []CodeExecutionResult

	// RequestJSON contains the raw API request for debugging (set on ChunkTypeComplete)
	RequestJSON []byte
	// ResponseJSON contains the raw API response for debugging (set on ChunkTypeComplete)
	ResponseJSON []byte
}

// ChunkType indicates the type of stream chunk
type ChunkType int

const (
	ChunkTypeText ChunkType = iota
	ChunkTypeUsage
	ChunkTypeCitation
	ChunkTypeComplete
	ChunkTypeError
	ChunkTypeToolCall
	ChunkTypeCodeExecution
)
